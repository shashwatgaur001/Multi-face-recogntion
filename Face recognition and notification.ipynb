{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee838148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960f8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier= cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4095c245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-3-131a3713cc69>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "def face_extractor(img):\n",
    "    gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.array(gray, dtype='uint8')\n",
    "    faces= face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    for(x,y,w,h) in faces:\n",
    "        cropped=img[y:y+h,x:x+w]\n",
    "    return cropped\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b53b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "count=0\n",
    "\n",
    "while True:\n",
    "    ret, frame= cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count+=1\n",
    "        face=cv2.resize(face_extractor(frame),(200,200))\n",
    "        face=cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path='./faces/user/'+str(count)+'.jpg'\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow('Face crop',face)\n",
    "        \n",
    "    else:\n",
    "        print(\"NOTHING\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(10)==13 or count==100:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Collected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76aee7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<face_LBPHFaceRecognizer 00000223FC3BAA90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "\n",
    "data_path='./faces/user/'\n",
    "\n",
    "onlyfiles=[f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "training, labels=[],[]\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    img_pth=data_path+onlyfiles[i]\n",
    "    images=cv2.imread(img_pth,cv2.IMREAD_GRAYSCALE)\n",
    "    training.append(np.asarray(images,dtype=np.uint8))\n",
    "    labels.append(i)\n",
    "    \n",
    "labels=np.asarray(labels, dtype=np.int32)\n",
    "model=cv2.face_LBPHFaceRecognizer.create()\n",
    "model.train(np.asarray(training),np.asarray(labels))\n",
    "print(\"Training done\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9a5fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\env1\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<face_LBPHFaceRecognizer 00000223FCA5EC90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "data_path1='./facenew/user2/'\n",
    "\n",
    "onlyfiles1=[f for f in listdir(data_path1) if isfile(join(data_path1,f))]\n",
    "training1, labels1=[],[]\n",
    "for i,files in enumerate(onlyfiles1):\n",
    "    img_pth1=data_path1+onlyfiles1[i]\n",
    "    images1=cv2.imread(img_pth1,cv2.IMREAD_GRAYSCALE)\n",
    "    training1.append(np.asarray(images1,dtype=np.uint8))\n",
    "    labels1.append(i)\n",
    "    \n",
    "labels1=np.asarray(labels1, dtype=np.int32)\n",
    "model1=cv2.face_LBPHFaceRecognizer.create()\n",
    "model1.train(np.asarray(training1),np.asarray(labels1))\n",
    "print(\"Training done\")\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ed1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbbf4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be51e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9793b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywhatkit as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eeecce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import subprocess\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e607c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-12-3e4e72e722af>:5: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "face_classifier=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def face_detector(img, size=0.5):\n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces= face_classifier.detectMultiScale(gray,1.3,5,0)\n",
    "    if faces is ():\n",
    "        return img,[]\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi=img[y:y+h,x:x+w]\n",
    "        roi=cv2.resize(roi,(200,200))\n",
    "        return img, roi\n",
    "    \n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "def confidence(results, image):\n",
    "    if results[1] < 500 :\n",
    "        confidence = int( 100 * (1 - (results[1])/400) )\n",
    "        display_string = str(confidence) + '% Confident it is User'\n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "    return confidence\n",
    "\n",
    "while True:\n",
    "    ret,  frame= cap.read()\n",
    "    image,face=face_detector(frame)\n",
    "    try:\n",
    "        face=cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        results=model.predict(face)\n",
    "        results1=model1.predict(face)\n",
    "        \n",
    "        face1= confidence(results, image)\n",
    "        face2 = confidence(results1, image)\n",
    "        \n",
    "        \n",
    "        if face1 > 80:\n",
    "            cv2.putText(image, \"Shashwat Gaur\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            import smtplib\n",
    "\n",
    "            gmail_user = \"shashwatgaur001@gmail.com\"\n",
    "            gmail_pwd = \"pass\"\n",
    "            TO = 'email@email.com'\n",
    "            SUBJECT = \"Check mail\"\n",
    "            TEXT = \"content\"\n",
    "            server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "            server.ehlo()\n",
    "            server.starttls()\n",
    "            server.login(gmail_user, gmail_pwd)\n",
    "            BODY = '\\r\\n'.join(['To: %s' % TO,\n",
    "                    'From: %s' % gmail_user,\n",
    "                    'Subject: %s' % SUBJECT,\n",
    "                    '', TEXT])\n",
    "\n",
    "            server.sendmail(gmail_user, [TO], BODY)\n",
    "            print ('email sent')\n",
    "            \n",
    "            pk.sendwhatmsg(\"+91contact _no\", \n",
    "                        \"Hello\", \n",
    "                        13, 12)\n",
    "            print(\"Successfully Sent!\")\n",
    "\n",
    "            \n",
    "            if cv2.waitKey(10)==13:\n",
    "                break\n",
    "                cv2.destroyAllWindows()\n",
    " \n",
    "                    \n",
    "           \n",
    "             \n",
    "\n",
    "            \n",
    "        elif face2 > 80:\n",
    "            cv2.putText(image, \"USER2\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            instance_id = sp.getoutput(\"aws ec2 run-instances --image-id ami-011c99152163a87ae --instance-type t2.micro --count 1 --subnet-id subnet-0d4e2bb1599be8952 --security-group-ids sg-09a168c7c84e06582 --key-name MyfirstawsKey  --tag-specifications ResourceType=instance,Tags=[{Key=Name,Value=cvTask_Instance}]  --query Instances[*].[InstanceId] --output text\")\n",
    "            print(\"Instance Id : \"+str(instance_id))\n",
    "            volume_id = sp.getoutput(\"aws ec2 create-volume --volume-type gp2 --availability-zone ap-south-1a --size 5 --tag-specifications=ResourceType=volume,Tags=[{Key=Name,Value=cvTask_volume}] --query VolumeId --output text\")\n",
    "            print(\"Volume Id : \"+str(volume_id) )\n",
    "            time.sleep(20)\n",
    "            sp.getoutput(\"aws ec2 attach-volume --volume-id {} --instance-id {} --device /dev/sdf\".format(volume_id,instance_id))\n",
    "            print(\"Volume and Instance Attached\")\n",
    "            if cv2.waitKey(10)==13:\n",
    "                break\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "                \n",
    "        else:    \n",
    "            cv2.putText(image, \"idk who\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "            \n",
    "          \n",
    "\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image,\"Nope idk\",(220,120),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image,\"Lets see\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.imshow('Face recognition', image)\n",
    "        pass\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9977ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796298a",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
